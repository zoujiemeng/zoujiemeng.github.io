---
layout: post
title: "MIT 6.00.2x 计算思维和数据科学导论 课程笔记"
tagline: ""
description: "MIT 6.00.2x 计算思维和数据科学导论 课程笔记"
category: python
tags: [python,tips]
last_updated: 2018-07-12
---

本文是在线课程`MIT 6.00.2X 计算思维和数据科学导论`的学习笔记，主要用来记录一些易忽略以及重要的知识点，文章按照课程顺序记录。

## 第一讲-绘图
Numpy-->Scipy-->MatPlotLib-->PyLab, Pylab在Python里面构筑了一个与MATLAB非常类似的绘图工具，对于熟悉MATLAB的码农来说非常好上手。
### 简单函数
首先必须`import pylab`
+ pylab.figure(1)：第一次运行创建图1，第二次及之后表示切换至图1
+ pylab.plot(x,y,'ro'):xy长度需相同，可以只有y，此时x会变成0~(len(y)-1),'ro'与matlab一致，还可以使用linewidth等关键词参数
+ pylab.show()：必须运行该命令图表才会显示在屏幕上
+ pylab.savefig('figure_file_name'):将图表存成png文件,位于当前文件夹下
+ pylab.title('figure_title')
+ pylab.xlabel('xlabel_str')
+ pylab.ylabel('ylabel_str')
+ pylab.legend(loc = 'best')：图例，loc相当于matlab的location关键字，best意为程序自动寻找最佳位置
### 最后一个例子说明Python是支持多继承的同时可以用pylab画多张图可视化算法结果

## 第二讲 模拟和随机游走
+ 近代出现很多数学上无法精确建模的问题，例如布朗运动，量子物理，这里面存在着随机性，计算机能够在一定程度上解决这些问题。事实上，针对这类问题，所有的模型都是错误的，但是有一部分是有用的。
+ Python里面随机数需要`import random`
+ random.choice(var)在var里面随机取值
+ 可以用random.seed(int)设定随机数种子
+ random.random()返回0-1之间的随机数

## 第三讲 概率和哈希
+ 用python可以直观模拟概率问题，多次试验之后能够匹配理论结果
+ ord(c)返回字符c的int值，8bit存储，转换成字符
+ hash的本质是用空间换时间，这很值，因为时间太重要了

## 第四讲 随即编程和统计思维
+ 大数定理：在试验不变的条件下，重复试验多次，随机事件的频率近似于它的概率。
+ pylab.semilogx()将当前figure的x轴变为log对数，这样能够比较好的观察数值低的时候曲线的情况
+ pylab.text(x,y,str)在figure的x,y位置显示str内容
+ pylab.hist(A,bins=n)画直方图，显示A中个数字出现的频率，将min(A)-max(A)进行n等分
+ pylab.xlim()无参数返回画图时坐标轴的xmin和xmax
+ pylab.xlim(xmin,xmax)有参数是设定坐标轴的x区间

## 第五讲 蒙特卡洛模拟
+ 蒙特卡罗方法的基本思想：当所要求解的问题是某种事件出现的概率，或者是某个随机变量的期望值时，它们可以通过某种“试验”的方法，得到这种事件出现的频率，或者这个随机变数的平均值，并用它们作为问题的解。
+ 对于正态分布（Normal distribution），距离平均值两个标准差之内的部分的比率合起来为95%，因此要使符合这一特性的模拟实验达到95%以上的置信率，则标准差需要小于(1-0.95)/2

## 第六讲 利用随机性解决非随机问题
+ random.gauss(mean,sd)生成高斯分布序列
+ 对于正态分布（Normal distribution），距离平均值一个标准差之内的部分的比率合起来为68%，两个标准差之内的部分的比率合起来为95%，三个标准差之内的部分的比率合起来为99%。
+ 常见的分布形态除了正态分布之外，还有均匀分布和指数分布。均匀分布一般存在于人类设计的游戏中，比如掷骰子，掷硬币等，在自然中比较少出现。指数分布相对而言更常见一些，例如人体内药物的稀释过程以及原子的衰变就是典型的指数衰减过程，而复利则是典型的指数上升过程。
+ pylab.pie()画饼状图
+ monty hall problem可以用模拟的方式得到结果

## 第七讲 曲线拟合
+ pylab.polyfit(x,y,1)多项式拟合，最后一个参数为最高次项
+ 衡量一个曲线拟合的好坏看可决系数的值（coefficient of determination），其计算方法为1-(回归拟合值减去测量值的平方和/测量值减去测量均值的平方和)，该值越靠近1说明拟合曲线越接近真实值

## 第八讲 背包问题
+ 在给定的重量限制内装下价值最高的物品组合就是背包问题的简单描述，背包问题的成熟解决方案为贪婪算法。
+ 贪婪算法的简单描述：先选择best，在选择second best，以此顺序，直到达到或超过限制条件。
+ 对于一个物品序列，以0代表不选择该物品，1代表选择该物品，则物品选择的组合可以用二进制的bits来表示
+ 有时，穷举法（brute force approach）能够获得最佳的解，原因是贪婪算法中选择best的策略不对或者根本就没有更好的选择方法。
+ 对于这类0或1的问题，首先可以考虑二叉树（决策树）的解法，该解法可能非常有效且比穷举法更快一些。不过，对于01背包问题，二叉树的方法复杂度也仍然是指数级（其只是剪掉了那些超过限制条件的枝叶），因为该问题的固有复杂度是指数级的。因此对于这类问题，如果想更快的获得一个可行的解决方案，贪婪算法也不失为一个很好的选择，这中间有trade off。
+ 背包问题elegant的解决方案是动态规划
+ 对于斐波那契数列生成这类问题，双递归是最直白简单的写法，然而实际计算中做了大量重复计算，此时可以使用一个字典类型的变量记住之前计算过的值，然后通过查找的方法直接取出，这样能减少算法复杂度

## 第九讲 图与图优化
DFS的python实现

```python
def DFS(graph, start, end, path = [], shortest = None):
    #assumes graph is a Digraph
    #assumes start and end are nodes in graph
    path = path + [start]
    print 'Current dfs path:', printPath(path)
    if start == end:
        return path
    for node in graph.childrenOf(start):
        if node not in path: #avoid cycles
            newPath = DFS(graph,node,end,path,shortest)
            if newPath != None:
                return newPath

def DFSShortest(graph, start, end, path = [], shortest = None):
    #assumes graph is a Digraph
    #assumes start and end are nodes in graph
    path = path + [start]
    print 'Current dfs path:', printPath(path)
    if start == end:
        return path
    for node in graph.childrenOf(start):
        if node not in path: #avoid cycles
            if shortest == None or len(path)<len(shortest):
                newPath = DFSShortest(graph,node,end,path,shortest)
                if newPath != None:
                    shortest = newPath
    return shortest
```

BFS的python实现

```python
def BFS(graph, start, end, q = []):
    initPath = [start]
    q.append(initPath)
    while len(q) != 0:
        tmpPath = q.pop(0)
        lastNode = tmpPath[len(tmpPath) - 1]
        print 'Current dequeued path:', printPath(tmpPath)
        if lastNode == end:
            return tmpPath
        for linkNode in graph.childrenOf(lastNode):
            if linkNode not in tmpPath:
                newPath = tmpPath + [linkNode]
                q.append(newPath)
    return None
```

## 第十讲 图进阶
+ 移动板块解谜的问题可以转化成图问题来解决，要生成所有的情况非常困难，因为实际图太大，这时可用生成图解决，即在进行BFS或者DFS的同时生成edges。对于这类问题BFS和DFS都能在理论上解决，但是实际上DFS很可能因为其占用内存过多报错。
+ 最大子集问题可以通过转化成图来解决，最简单的方法是穷举法，即生成所有的power set然后一一判定。

## 第十一讲 机器学习
+ All models are wrong, but some are useful --George Box
+ marketing is the art of getting people to buy things they don`t actually need
+ 机器学习与一般编程的区别
![diff-ml-from-nm]({{site.url}}/assets/images/20180719-1.png)
+ 曼哈顿距离与欧式距离的区别于统一
![mdis-edis]({{site.url}}/assets/images/20180719-2.png)

## 第十二讲 机器学习（二）
+ k-means聚类描述简单，然而可优化的地方多。最初的随机取点可优化，k的取值如果不确定的话可在一定范围内进行优化。
+ 有时候多种特征在一起时，由于其均值和sd不在一个级别，所以需要做一个feature scale，一般用$$x^{`}=\frac{x-\mu_x}{\sigma_x}$$公式，该公式使得特征值的均值变为0，sd变为1

## 第十三讲 统计悖论
+ 统计结果可能造成错觉，例如拟合的结果、图表中不恰当的y轴选择
+ correlation does not imply causation
+ 取样可能造成结论的偏差，一般的要求是研究整体的随机取样，然而事实上研究者更倾向于容易取样的点。例如大学里进行的统计实例很可能都是学生参加的，这样无法反应社会的问题。

## bonus 动态规划
+ 有的时候得到最优解的算法非常复杂，此时可考虑动态规划，能够大量缩短运行时间
+ 如果有计算的重复，可以用memoization的方法来记住原来的结果，以后重复使用的时候只需查表即可。python还有一种特殊的语法能够实现该功能：

```python
# works for functions with hashable (immuatble) arguments
# Example usage: fib = memoize(fib)
def memoize(f):
  def memf(*x):
    if x not in memf.cache:
      memf.cache[x] = f(*x)
    return memf.cache[x]
   memf.cache = {}
   return memf
```
+ 背包问题，FINDING LINE BREAKS问题，DNA序列比对问题这类可以分解成subquestion的问题都可以使用上述memoization的方法去除重复的计算，能避免指数级复杂度的情况。
